# -*- coding: utf-8 -*-
"""Muhammad Fazal - Practise Case EDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lLG3upnEbgSoKMkBamFJHu0tClCqyhYZ

# Muhammad Fazal Hildiansyah - DS2

## Import Library
> Hal pertama yg dilakukan adalah import library yang akan digunakan pada analisa kita
"""

# import libraries
import pandas as pd
import seaborn as sns
from scipy.stats import shapiro

# import scaler dari sckit-learn untuk scala point
from sklearn.preprocessing import MinMaxScaler

# import warning agar tidak muncul warning terus di google colab
import warnings
warnings.filterwarnings("ignore")

"""## Data extraction
> Setelah itu, mulai dari Data Pre-processing, start dari extract data dari source yg akan digunakan
"""

# Baca datasource dari CSV
df = pd.read_csv('https://raw.githubusercontent.com/fazalh/fellowship-ds2-eda/main/epl_1819.csv', thousands=',')

# Check data ada berapa column dan row
df.shape

"""## Data cleansing
> soal nomor 1 termasuk dari cleansing

### 1. Whether this data is clean?
"""

# karena ini adalah data per team, kita check dulu apakah tidak ada duplicate data
df['Team'].is_unique

# Check column mana yg paling banyak missing values

df_check = df.isnull().sum().sort_values(ascending=False)

df_check[df_check > 0]

# Check data types tiap column
# sebelum kita perbaiki saat extract data, terdapat beberapa data yg menjadi object yaitu :
# attack_passes, attack_passes_long, attack_passes_back, defence_clearance
df.dtypes

df.describe()

"""> Kesimpulan dari Nomor 1 adalah data not clean. Proses cleansing dimulai dengan penyesuaian saat read csv harus ada parameter thousands agar yang ada comma tidak menjadi string/object. Setelah itu kita check duplicates team, check missing values dan describe.

### 2. How is the point distribution of the epl team? and which team is an anomaly?
"""

# Check distribution dari general points

sns.kdeplot(df['general_points'], shade=True)

# Diperoleh hasil yg normal distribution

# kita check data anomali menggunakan boxplot

ax = sns.boxplot(data=df['general_points'], orient="h")

# Diperoleh hasil tidak ada anomali pada general_points

# Uji normalitas dengan Shapiro Wilk Test

stat, p = shapiro(df['general_points'])
print('Statistics=%.3f, p=%.3f' % (stat, p))
alpha = 0.05
if p > alpha:
	print('Sample looks Gaussian (fail to reject H0)')
else:
	print('Sample does not look Gaussian (reject H0)')
 

 # Hasil Uji normalitas juga menunjukkan tidak ada anomaly karena p > alpha

"""## Data Analysis

### 3. Which team has the best attack?
"""

# kita buat dataframe untuk soal nomor 3
attack = df[['Team','attack_pass_accuracy','attack_posession','attack_shots_on_target','attack_scored']].reset_index()

# gunakan MinMaxScaler dengan range dari 0 - 1
scaler = MinMaxScaler(feature_range=(0,1))

# pisahkan number dan category
attack_number = attack[['attack_pass_accuracy','attack_posession','attack_shots_on_target','attack_scored']]
attack_name = attack['Team']

# run scaler dan jadikan dataframe presult
scaler.fit(attack_number)
attack_result = pd.DataFrame(scaler.transform(attack_number))

# Jumlahkan semua hasil parameter kolom score
attack_result['score'] = attack_result.sum(axis=1)

# kita gabungkan dengan dataframe attack_name dan sort values descending based on Score
attack = pd.concat([attack_name, attack_result], axis=1, sort=False)
attack = attack.sort_values(by=['score'], ascending=False)
print(attack.head())
print('\r')

# Bar Chart top 5 
ax = sns.barplot(y=attack['Team'], x=attack['score'], data=attack, palette="Blues_r").set_title('Best Attack Teams Chart')

print('The best team attack is ' + attack['Team'][attack['score'] == attack['score'].max()])

"""### 4. Which team has the best defense?"""

# Hitung jumlah kebobolan berbanding dengan defence tim tersebut
# semakin rendah, semakin baik team tersebut dalam defence
df['defence_rate'] = df['defence_goals_conceeded'] /(df['defence_blocks'] + df['defence_saves'])


# kita pisahkan untuk data defence dan sort values based on defence rate
defence = df[['Team','defence_goals_conceeded','defence_blocks','defence_saves','defence_rate']].sort_values(by=['defence_rate'])
print(defence.head())
print('\r')

# Bar Chart top 5 
ax = sns.barplot(y=defence['Team'], x=defence['defence_rate'], data=defence, palette="Reds_r").set_title('Best Defence Teams (Lower is Better)')

print('The best team defence is ' + defence['Team'][defence['defence_rate'] == defence['defence_rate'].min()])

"""### 5. Which team is good in financial aspect?"""

# kita buat dataframe untuk soal nomor 5

finance = df[['Team','finance _market_average','finance _team_market','finance _tv_revenue']].reset_index()

# gunakan MinMaxScaler dengan range dari 0 - 1
scaler = MinMaxScaler(feature_range=(0,1))

# pisahkan number dan category
finance_number = finance[['finance _market_average','finance _team_market','finance _tv_revenue']]
finance_name = finance['Team']

# run scaler dan jadikan dataframe presult
scaler.fit(finance_number)
finance_result = pd.DataFrame(scaler.transform(finance_number))

# Jumlahkan semua hasil parameter kolom score
finance_result['score'] = finance_result.sum(axis=1)

# kita gabungkan dengan dataframe finance_name dan sort values descending based on Score
finance = pd.concat([finance_name, finance_result], axis=1, sort=False)
finance = finance.sort_values(by=['score'], ascending=False)
print(finance.head())
print('\r')

# Bar Chart top 5 
ax = sns.barplot(y=finance['Team'], x=finance['score'].sort_values(ascending=False), data=finance, palette="Greens_r").set_title('Good Teams in Financial Aspect')

print('The good team in financial is ' + finance['Team'][finance['score'] == finance['score'].max()])

"""### 6. Creativity

#### Which team is the worst in violation and have lost the most?
"""

# kita buat dataframe untuk soal nomor 6

worst = df[['Team','general_card_red','general_card_yellow','general_lost']].reset_index()

# gunakan MinMaxScaler dengan range dari 0 - 1
scaler = MinMaxScaler(feature_range=(0,1))

# pisahkan number dan category
worst_number = worst[['general_card_red','general_card_yellow','general_lost']]
worst_name = worst['Team']

# run scaler dan jadikan dataframe worst_result
scaler.fit(worst_number)
worst_result = pd.DataFrame(scaler.transform(worst_number))

# Jumlahkan semua hasil parameter kolom score
worst_result['score'] = worst_result.sum(axis=1)

# kita gabungkan dengan dataframe worst_name dan sort values descending based on Score
worst = pd.concat([worst_name, worst_result], axis=1, sort=False)
worst = worst.sort_values(by=['score'], ascending=False)
print(worst.head())
print('\r')

# Bar Chart top 5 
ax = sns.barplot(y=worst['Team'].head(), x=worst['score'].head().sort_values(ascending=False), data=worst, palette="Oranges_r").set_title('Top 5 Worst Teams in Violation and Lost')

print('The worst team is ' + worst['Team'][worst['score'] == worst['score'].max()])

"""#### Is there any correlation between Lost, Red, and Yellow Card ?"""

lost_red = df[['Team','general_card_red','general_card_yellow','general_lost']]

corrMatrix = lost_red.corr()
sns.heatmap(corrMatrix, annot=True)
plt.show()

"""## Finish"""